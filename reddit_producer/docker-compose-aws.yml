# =====================================================================
# docker-compose.aws.yml â€” EC2 t2.micro deployment (1GB RAM)
# Single broker, single processing replica, no Postgres replica
# =====================================================================

version: "3.9"

x-postgres-env: &postgres-env
  POSTGRES_DB:       reddit
  POSTGRES_USER:     reddit
  POSTGRES_PASSWORD: reddit

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME:   2000
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout:   5s
      retries:   5
    deploy:
      resources:
        limits:
          memory: 256m

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS:            INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_HEAP_OPTS: "-Xmx256m -Xms128m"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout:   10s
      retries:   15
    deploy:
      resources:
        limits:
          memory: 400m

  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka_init
    depends_on:
      kafka: { condition: service_healthy }
    volumes:
      - ./kafka-init.sh:/kafka-init.sh:ro
    entrypoint: ["/bin/sh", "/kafka-init.sh"]
    command: >
      "
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists
        --topic reddit.posts.raw     --replication-factor 1 --partitions 3;
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists
        --topic reddit.posts.refresh --replication-factor 1 --partitions 3;
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists
        --topic reddit.posts.dlq     --replication-factor 1 --partitions 1;
      echo 'Topics created.';
      "

  postgres:
    image: timescale/timescaledb:latest-pg15
    container_name: postgres
    environment:
      <<: *postgres-env
      POSTGRES_INITDB_ARGS: "--auth-host=trust --auth-local=trust"
      POSTGRES_HOST_AUTH_METHOD: trust
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./pg_hba.conf:/pg_hba.conf:ro
      - ./storage/schema.sql:/docker-entrypoint-initdb.d/01_schema.sql:ro
    ports:
      - "5433:5432"
    command: >
      postgres
        -c hba_file=/pg_hba.conf
        -c shared_buffers=128MB
        -c work_mem=4MB
        -c max_connections=50
        -c wal_level=minimal
        -c max_wal_senders=0
        -c listen_addresses='*'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U reddit"]
      interval: 5s
      timeout:  5s
      retries:  10
    deploy:
      resources:
        limits:
          memory: 300m

  migrate:
    build:
      context: .
      dockerfile: processing/Dockerfile
    container_name: reddit_migrate
    command: sh -c "sleep 20 && python -m storage.migrate"
    env_file: .env
    environment:
      POSTGRES_HOST:     postgres
      POSTGRES_PORT:     5432
      POSTGRES_DB:       reddit
      POSTGRES_USER:     reddit
      POSTGRES_PASSWORD: reddit
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"

  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --maxmemory 128mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout:  3s
      retries:  5
    deploy:
      resources:
        limits:
          memory: 150m

  ingestion:
    build:
      context: .
      dockerfile: ingestion/Dockerfile
    container_name: reddit_ingestion
    env_file: .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      POSTGRES_HOST:           postgres
      POSTGRES_PORT:           5432
      POSTGRES_DB:             reddit
      POSTGRES_USER:           reddit
      POSTGRES_PASSWORD:       reddit
      SCHEDULER_CONFIG_POLL_S: "60"
    depends_on:
      kafka-init: { condition: service_completed_successfully }
      migrate:    { condition: service_completed_successfully }
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256m

  processing:
    build:
      context: .
      dockerfile: processing/Dockerfile
    container_name: reddit_processing
    env_file: .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      POSTGRES_HOST:     postgres
      POSTGRES_PORT:     5432
      REDIS_URL:         redis://redis:6379
      METRICS_PORT:      "8000"
      CHANNEL_LAYER_URL: redis://redis:6379/2
    ports:
      - "8010:8000"
    depends_on:
      kafka-init: { condition: service_completed_successfully }
      postgres:   { condition: service_healthy }
      redis:      { condition: service_healthy }
      migrate:    { condition: service_completed_successfully }
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 300m

  dlq-consumer:
    build:
      context: .
      dockerfile: processing/Dockerfile
    container_name: reddit_dlq
    command: python -m processing.dlq_consumer
    env_file: .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      REDIS_URL:       redis://redis:6379
      DLQ_REPLAY_PORT: "8001"
    ports:
      - "8001:8001"
    depends_on:
      kafka-init: { condition: service_completed_successfully }
      redis:      { condition: service_healthy }
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128m

  django:
    build:
      context: ..
      dockerfile: Dockerfile.django
    container_name: reddit_django
    command: daphne -b 0.0.0.0 -p 8080 config.routing:application
    env_file: .env
    environment:
      DJANGO_SETTINGS_MODULE: config.settings
      POSTGRES_HOST:          postgres
      POSTGRES_PORT:          5432
      REDIS_URL:              redis://redis:6379
      DJANGO_ALLOWED_HOSTS:   "localhost,127.0.0.1,django"
    ports:
      - "8080:8080"
    depends_on:
      postgres: { condition: service_healthy }
      redis:    { condition: service_healthy }
      migrate:  { condition: service_completed_successfully }
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256m

  dashboard:
    build:
      context: ../../dashboard_v4
      dockerfile: Dockerfile.dashboard
    container_name: reddit_dashboard
    ports:
      - "3000:3000"
    depends_on:
      - django
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256m

  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
      - "--web.enable-lifecycle"
    depends_on:
      - processing
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128m

  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /etc/grafana/dashboards/processing.json
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128m

volumes:
  pg_data:
  prometheus_data:
  grafana_data: